{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5c0da8-897a-41e0-bbfd-c4f642a86e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from brpylib import NsxFile\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import direct_neural_biasing as dnb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b270a-1aae-435f-9b42-0e8b64898b46",
   "metadata": {},
   "source": [
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73353c9f-767f-4d41-b81d-5c8688a21a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = np.load('data/Patient2EEG.npy')\n",
    "mrk_file = 'data/Patient02_OfflineMrk.mrk'\n",
    "data = data_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc045c93-03f6-49e3-91cf-60f92ee67df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a8d803-a765-4521-aaab-22f7e6795e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_stream_section(data_stream, n, m):\n",
    "    \"\"\"\n",
    "    Plots an n-m section of a 1D integer data stream as a line graph.\n",
    "\n",
    "    Args:\n",
    "        data_stream (list or numpy.ndarray): The 1D integer data stream.\n",
    "        n (int): The starting index (inclusive).\n",
    "        m (int): The ending index (inclusive).\n",
    "    \"\"\"\n",
    "    section = data_stream[n : m + 1]\n",
    "    indices = range(n, m + 1)\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(indices, section)\n",
    "    plt.title(f'Data Section {n} to {m}')\n",
    "    plt.xlabel('Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "start_t = 2515\n",
    "end_t = 4515\n",
    "\n",
    "plot_data_stream_section(data, start_t, end_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2da24-28e0-4b65-838a-d09b7756b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Concise .mrk file parser ---\n",
    "def parse_mrk_file_concise(filepath):\n",
    "    \"\"\"\n",
    "    Parses a .mrk file into a dictionary (signal_type: [indices]).\n",
    "    Assumes first line is header, subsequent lines are 'index index signal_type'.\n",
    "    \"\"\"\n",
    "    mrk_data = {}\n",
    "    with open(filepath, 'r') as f:\n",
    "        next(f) # Skip header line\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 3:\n",
    "                index = int(parts[0])\n",
    "                signal_type = parts[2]\n",
    "                mrk_data.setdefault(signal_type, []).append(index)\n",
    "    return mrk_data\n",
    "\n",
    "def plot_marker_with_context(data_stream, marker_index, signal_type, context_window=500, output_dir=\"marker_plots\"):\n",
    "    \"\"\"\n",
    "    Plots a single marker with surrounding data context.\n",
    "    \"\"\"\n",
    "    marker_index = int((marker_index / 512) * 30000) # adjust for differe3nces in sample rate\n",
    "    data_length = len(data_stream)\n",
    "    plot_start = max(0, marker_index - context_window)\n",
    "    plot_end = min(data_length - 1, marker_index + context_window)\n",
    "\n",
    "    section_data = data_stream[plot_start : plot_end + 1]\n",
    "    section_indices = range(plot_start, plot_end + 1)\n",
    "\n",
    "    # CORRECTED LINE: Check if the section_data is empty using its length/size\n",
    "    if len(section_data) == 0: # or if section_data.size == 0: if you're sure it's a numpy array\n",
    "        print(f\"Skipping plot for marker {marker_index} ({signal_type}) due to empty data section.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    plt.plot(section_indices, section_data, label='Continuous Data', color='blue', linewidth=1.5)\n",
    "\n",
    "    # Highlight the marker point\n",
    "    plt.axvline(x=marker_index, color='red', linestyle='--', label=f'Marker: {signal_type}')\n",
    "    # Ensure the marker_index is within the bounds of data_stream before trying to access it\n",
    "    if 0 <= marker_index < data_length:\n",
    "        plt.plot(marker_index, data_stream[marker_index], 'ro', markersize=8, label='Marker Location')\n",
    "    else:\n",
    "        print(f\"Warning: Marker index {marker_index} is out of bounds for data_stream. Cannot plot marker point.\")\n",
    "\n",
    "\n",
    "    plt.title(f'Signal Type: {signal_type} at Index: {marker_index} (Context: $\\pm${context_window})')\n",
    "    plt.xlabel('Data Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.grid(True, linestyle=':', alpha=0.7)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d902839-094f-473e-9d8d-f2a357596fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Main Execution ---\n",
    "\n",
    "# 1. Parse the .mrk file\n",
    "parsed_markers = parse_mrk_file_concise(mrk_file)\n",
    "print(\"\\nParsed Markers:\")\n",
    "for signal_type, indices in parsed_markers.items():\n",
    "    print(f\"  {signal_type}: {indices[:5]}... ({len(indices)} total)\")\n",
    "\n",
    "# 2. Plot each marker with context (first 10, show only)\n",
    "context_window_size = 100000 # Adjust this to change how much data is shown around each marker\n",
    "max_plots_to_show = 5\n",
    "plots_shown_count = 0\n",
    "\n",
    "print(f\"\\nGenerating and displaying the first {max_plots_to_show} plots with context window of $\\pm${context_window_size}...\")\n",
    "\n",
    "# Iterate through signal types and their indices\n",
    "for signal_type, indices in parsed_markers.items():\n",
    "    for marker_index in indices:\n",
    "        if plots_shown_count < max_plots_to_show:\n",
    "            plot_marker_with_context(data, marker_index, signal_type, context_window=context_window_size)\n",
    "            plots_shown_count += 1\n",
    "        else:\n",
    "            # Once 10 plots are shown, break out of the inner loop\n",
    "            break\n",
    "    if plots_shown_count >= max_plots_to_show:\n",
    "        # If 10 plots are shown, break out of the outer loop too\n",
    "        break\n",
    "\n",
    "if plots_shown_count == 0:\n",
    "    print(\"No plots were generated. Check your .mrk file or data stream.\")\n",
    "else:\n",
    "    print(f\"\\nFinished displaying the first {plots_shown_count} marker plots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34192930-3ece-42aa-b1cf-706dd7f79c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "DirectNeuralBiasing Detection Comparison Script\n",
    "Compares detection results against a ground truth marker file, providing a\n",
    "detailed event-by-event summary and performance metrics with live updates.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "import direct_neural_biasing as dnb\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "# --- Constants ---\n",
    "DATA_FS = 30000.0\n",
    "MRK_FS = 512.0\n",
    "TOLERANCE_MS = 250\n",
    "CONTEXT_WINDOW_MS = 500 # Context window for live printing (+/- 500ms)\n",
    "PLOT_CONTEXT_MS = 1000  # Context window for plots (+/- 1 second)\n",
    "\n",
    "DATA_FILE_PATH = 'data/Patient2EEG.npy'\n",
    "MRK_FILE_PATH = 'data/Patient02_OfflineMrk.mrk'\n",
    "CONFIG_PATH = \"matlab_matched_config.yaml\"\n",
    "\n",
    "# Control flags\n",
    "SHOW_LIVE_PLOTS = True  # Set to False to disable live plotting\n",
    "MAX_LIVE_PLOTS = 10  # Maximum number of live plots to show (set to None for all)\n",
    "\n",
    "# Define a structured tuple for detection results for clarity\n",
    "Detection = namedtuple('Detection', [\n",
    "    'index', 'wave_start', 'wave_end', 'peak_amplitude', 'is_match',\n",
    "    'matched_gt_index', 'matched_gt_original_index', 'latency_ms'\n",
    "])\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "def get_matlab_matched_config() -> dict:\n",
    "    \"\"\"Returns a dictionary with parameters matching the MATLAB script.\"\"\"\n",
    "    # Original MATLAB parameters:\n",
    "    # sf = 512 Hz, fc_low = 0.25, fc_high = 4, refractory_s = 2.5\n",
    "    return {\n",
    "        'processor': {\n",
    "            'verbose': False,\n",
    "            'fs': DATA_FS,\n",
    "            'channel': 1,\n",
    "            'enable_debug_logging': False\n",
    "        },\n",
    "        'filters': {\n",
    "            'bandpass_filters': [\n",
    "                {'id': 'slow_wave_filter', 'f_low': 0.25, 'f_high': 4.0},\n",
    "                {'id': 'ied_filter', 'f_low': 80.0, 'f_high': 120.0}\n",
    "            ]\n",
    "        },\n",
    "        'detectors': {\n",
    "            'wave_peak_detectors': [{\n",
    "                'id': 'slow_wave_detector',\n",
    "                'filter_id': 'slow_wave_filter',\n",
    "                'z_score_threshold': 2.0,\n",
    "                'sinusoidness_threshold': 0.7,\n",
    "                'check_sinusoidness': True,  # MATLAB checks correlation\n",
    "                'wave_polarity': 'downwave',  # MATLAB detects negative waves\n",
    "                'min_wave_length_ms': 250.0,  # MATLAB min_ZeroCrossing_s * 1000\n",
    "                'max_wave_length_ms': 1000.0  # MATLAB max_ZeroCrossing_s * 1000\n",
    "            }, {\n",
    "                'id': 'ied_detector',\n",
    "                'filter_id': 'ied_filter',\n",
    "                'z_score_threshold': 2.5,\n",
    "                'sinusoidness_threshold': 0.0,\n",
    "                'check_sinusoidness': False,\n",
    "                'wave_polarity': 'upwave',\n",
    "                'min_wave_length_ms': None,\n",
    "                'max_wave_length_ms': None\n",
    "            }]\n",
    "        },\n",
    "        'triggers': {\n",
    "            'pulse_triggers': [{\n",
    "                'id': 'pulse_trigger',\n",
    "                'activation_detector_id': 'slow_wave_detector',\n",
    "                'inhibition_detector_id': 'ied_detector',\n",
    "                'inhibition_cooldown_ms': 2500.0, # refractory_s * 1000\n",
    "                'pulse_cooldown_ms': 0\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    "\n",
    "def create_config_file(config_path: str):\n",
    "    \"\"\"Creates a YAML configuration file from the MATLAB-matched parameters.\"\"\"\n",
    "    config = get_matlab_matched_config()\n",
    "    with open(config_path, 'w') as f:\n",
    "        yaml.dump(config, f, default_flow_style=False, indent=2)\n",
    "    print(f\"Created MATLAB-matched configuration file: {config_path}\")\n",
    "\n",
    "# --- Data Handling ---\n",
    "\n",
    "def parse_mrk_file(filepath: str) -> np.ndarray:\n",
    "    \"\"\"Parses a .mrk file and returns an array of original marker indices.\"\"\"\n",
    "    markers = []\n",
    "    with open(filepath, 'r') as f:\n",
    "        next(f)  # Skip header\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 3:\n",
    "                markers.append(int(parts[0]))\n",
    "    return np.array(markers)\n",
    "\n",
    "def get_ground_truth_map(original_indices: np.ndarray) -> dict:\n",
    "    \"\"\"Converts original MRK indices to the data sampling rate and returns a map.\"\"\"\n",
    "    converted_indices = (original_indices * DATA_FS / MRK_FS).astype(int)\n",
    "    return dict(zip(converted_indices, original_indices))\n",
    "\n",
    "# --- Live Plotting Function ---\n",
    "\n",
    "def plot_detection_context(data: np.ndarray, detection: Detection, gt_indices: np.ndarray, \n",
    "                          gt_map: dict, plot_number: int, plot_context_ms: float = PLOT_CONTEXT_MS):\n",
    "    \"\"\"Plots the signal context around a detection with markers.\"\"\"\n",
    "    context_samples = int((plot_context_ms / 1000) * DATA_FS)\n",
    "    det_idx = detection.index  # Now this is the wave start\n",
    "    \n",
    "    # Get context range\n",
    "    start_idx = max(0, det_idx - context_samples)\n",
    "    end_idx = min(len(data), det_idx + context_samples)\n",
    "    \n",
    "    # Create time axis in milliseconds relative to detection (wave start)\n",
    "    time_samples = np.arange(start_idx - det_idx, end_idx - det_idx)\n",
    "    time_ms = time_samples * 1000 / DATA_FS\n",
    "    \n",
    "    # Create figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot signal\n",
    "    plt.plot(time_ms, data[start_idx:end_idx], 'b-', alpha=0.7, linewidth=1, label='Raw Signal')\n",
    "    \n",
    "    # Mark detection point (wave start - downward zero crossing)\n",
    "    plt.axvline(x=0, color='red' if not detection.is_match else 'darkgreen', \n",
    "                linestyle='-', linewidth=2, alpha=0.8,\n",
    "                label=f'Detection Start ({\"TP\" if detection.is_match else \"FP\"})')\n",
    "    \n",
    "    # Mark wave end (upward zero crossing)\n",
    "    if detection.wave_end > 0:\n",
    "        wave_end_ms = (detection.wave_end - det_idx) * 1000 / DATA_FS\n",
    "        plt.axvline(x=wave_end_ms, color='orange', linestyle=':', linewidth=1.5, alpha=0.6,\n",
    "                   label='Wave End')\n",
    "        \n",
    "        # Highlight the full wave span\n",
    "        plt.axvspan(0, wave_end_ms, alpha=0.2, color='yellow', label='Detected Wave')\n",
    "    \n",
    "    # Plot nearby ground truth markers\n",
    "    markers_in_range = gt_indices[(gt_indices >= start_idx) & (gt_indices < end_idx)]\n",
    "    for i, gt_idx in enumerate(markers_in_range):\n",
    "        marker_time_ms = (gt_idx - det_idx) * 1000 / DATA_FS\n",
    "        original_idx = gt_map[gt_idx]\n",
    "        \n",
    "        # Highlight matched marker\n",
    "        if detection.is_match and gt_idx == detection.matched_gt_index:\n",
    "            plt.axvline(x=marker_time_ms, color='green', linestyle='--', linewidth=2, alpha=0.8,\n",
    "                       label=f'Matched GT (Original: {original_idx})')\n",
    "        else:\n",
    "            plt.axvline(x=marker_time_ms, color='gray', linestyle='--', linewidth=1, alpha=0.5,\n",
    "                       label='GT Marker' if i == 0 else '')\n",
    "            # Add text label for original index\n",
    "            plt.text(marker_time_ms, plt.ylim()[1] * 0.9, f'{original_idx}', \n",
    "                    rotation=90, fontsize=8, color='gray', alpha=0.7)\n",
    "    \n",
    "    # Add detection info to title\n",
    "    title = f\"Detection #{plot_number} at wave start index {det_idx}\"\n",
    "    if detection.is_match:\n",
    "        title += f\" | ✅ TRUE POSITIVE | Latency: {detection.latency_ms:.1f} ms\"\n",
    "    else:\n",
    "        title += \" | ❌ FALSE POSITIVE\"\n",
    "    \n",
    "    if detection.peak_amplitude > 0:\n",
    "        title += f\" | Peak Z-score: {detection.peak_amplitude:.2f}\"\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time relative to wave start (ms)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend(loc='best')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Add zero line\n",
    "    plt.axhline(y=0, color='black', linestyle='-', linewidth=0.5, alpha=0.3)\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# --- Core Processing and Live Reporting ---\n",
    "\n",
    "def process_and_report_events_live(processor: dnb.PySignalProcessor, data: np.ndarray, gt_map: dict, chunk_size: int = 4096) -> tuple:\n",
    "    \"\"\"\n",
    "    Processes data, prints events live as they are detected, and returns final\n",
    "    lists of true positives, false positives, and false negatives.\n",
    "    \"\"\"\n",
    "    processor.reset_index()\n",
    "    \n",
    "    # --- Setup for live processing ---\n",
    "    true_positives, false_positives = [], []\n",
    "    gt_indices = np.array(list(gt_map.keys()))\n",
    "    matched_gt_mask = np.zeros(len(gt_indices), dtype=bool)\n",
    "    \n",
    "    # Convert tolerances to sample counts\n",
    "    tolerance_samples = int((TOLERANCE_MS / 1000) * DATA_FS)\n",
    "    context_samples = int((CONTEXT_WINDOW_MS / 1000) * DATA_FS)\n",
    "\n",
    "    num_chunks = (len(data) + chunk_size - 1) // chunk_size\n",
    "    pbar = tqdm(range(0, len(data), chunk_size), total=num_chunks, desc=\"🧠 Processing data\", unit=\"chunk\")\n",
    "    \n",
    "    plot_count = 0\n",
    "    \n",
    "    # --- Processing Loop ---\n",
    "    for i in pbar:\n",
    "        chunk = data[i:i + chunk_size].tolist()\n",
    "        chunk_output, _ = processor.run_chunk(chunk)\n",
    "\n",
    "        for sample_result in chunk_output:\n",
    "            if sample_result.get(\"detectors:slow_wave_detector:detected\", 0.0) == 1.0:\n",
    "                # Use wave_start_index to match MATLAB behavior (downward zero-crossing)\n",
    "                det_idx = int(sample_result.get(\"detectors:slow_wave_detector:wave_start_index\", -1))\n",
    "                \n",
    "                # --- Live Context and Matching ---\n",
    "                context_start, context_end = det_idx - context_samples, det_idx + context_samples\n",
    "                markers_in_window = [\n",
    "                    (gt_idx, gt_map[gt_idx]) for gt_idx in gt_indices \n",
    "                    if context_start <= gt_idx <= context_end\n",
    "                ]\n",
    "\n",
    "                # Find closest ground truth marker for potential match\n",
    "                distances = np.abs(gt_indices - det_idx)\n",
    "                min_dist_idx = np.argmin(distances)\n",
    "                \n",
    "                # Check if it's a valid match (within tolerance and not already matched)\n",
    "                if distances[min_dist_idx] <= tolerance_samples and not matched_gt_mask[min_dist_idx]:\n",
    "                    matched_gt_mask[min_dist_idx] = True\n",
    "                    gt_index = gt_indices[min_dist_idx]\n",
    "                    latency = (det_idx - gt_index) * 1000 / DATA_FS\n",
    "                    \n",
    "                    tp = Detection(\n",
    "                        index=det_idx,  # This is now the wave start (downward crossing)\n",
    "                        wave_start=det_idx,\n",
    "                        wave_end=int(sample_result.get(\"detectors:slow_wave_detector:wave_end_index\", -1)),\n",
    "                        peak_amplitude=sample_result.get(\"detectors:slow_wave_detector:peak_z_score_amplitude\", 0),\n",
    "                        is_match=True, matched_gt_index=gt_index,\n",
    "                        matched_gt_original_index=gt_map[gt_index], latency_ms=latency\n",
    "                    )\n",
    "                    true_positives.append(tp)\n",
    "                    \n",
    "                    # --- Live Print for True Positive ---\n",
    "                    tqdm.write(f\"  [✅ TRUE POSITIVE] Detection at index {tp.index:<9} | Matched MRK: {tp.matched_gt_index} (Original: {tp.matched_gt_original_index})\")\n",
    "\n",
    "                else:\n",
    "                    fp = Detection(\n",
    "                        index=det_idx,  # This is now the wave start (downward crossing)\n",
    "                        wave_start=det_idx,\n",
    "                        wave_end=int(sample_result.get(\"detectors:slow_wave_detector:wave_end_index\", -1)),\n",
    "                        peak_amplitude=sample_result.get(\"detectors:slow_wave_detector:peak_z_score_amplitude\", 0),\n",
    "                        is_match=False, \n",
    "                        matched_gt_index=None, \n",
    "                        matched_gt_original_index=None, \n",
    "                        latency_ms=None\n",
    "                    )\n",
    "                    false_positives.append(fp)\n",
    "\n",
    "                    # --- Live Print for False Positive ---\n",
    "                    marker_info = f\"Nearby MRKs: {[orig for _, orig in markers_in_window]}\" if markers_in_window else \"No nearby MRKs\"\n",
    "                    tqdm.write(f\"  [❌ FALSE POSITIVE] Detection at index {fp.index:<9} | {marker_info}\")\n",
    "                \n",
    "                # --- Live Plot ---\n",
    "                if SHOW_LIVE_PLOTS and (MAX_LIVE_PLOTS is None or plot_count < MAX_LIVE_PLOTS):\n",
    "                    plot_count += 1\n",
    "                    # Get the most recent detection\n",
    "                    current_detection = true_positives[-1] if true_positives and true_positives[-1].index == det_idx else false_positives[-1]\n",
    "                    \n",
    "                    # Temporarily clear the progress bar for clean plotting\n",
    "                    pbar.clear()\n",
    "                    plot_detection_context(data, current_detection, gt_indices, gt_map, plot_count)\n",
    "                    pbar.refresh()\n",
    "                \n",
    "                # Update progress bar postfix\n",
    "                pbar.set_postfix(TPs=len(true_positives), FPs=len(false_positives), refresh=True)\n",
    "\n",
    "    # --- Finalize ---\n",
    "    unmatched_gt_indices = gt_indices[~matched_gt_mask]\n",
    "    false_negatives = sorted([(int(gt_idx), gt_map[gt_idx]) for gt_idx in unmatched_gt_indices])\n",
    "\n",
    "    return sorted(true_positives), sorted(false_positives), false_negatives\n",
    "\n",
    "\n",
    "# --- Reporting & Visualization ---\n",
    "\n",
    "def print_summary_metrics(tp_count, fp_count, fn_count, total_gt):\n",
    "    \"\"\"Calculates and prints summary performance metrics.\"\"\"\n",
    "    sensitivity = tp_count / (tp_count + fn_count) if (tp_count + fn_count) > 0 else 0\n",
    "    precision = tp_count / (tp_count + fp_count) if (tp_count + fp_count) > 0 else 0\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"📊 FINAL SUMMARY METRICS\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total Ground Truth Events: {total_gt}\")\n",
    "    print(f\"Total Detected Events:   {tp_count + fp_count}\")\n",
    "    print(\"-\" * 28)\n",
    "    print(f\"True Positives:          {tp_count}\")\n",
    "    print(f\"False Positives:         {fp_count}\")\n",
    "    print(f\"False Negatives:         {fn_count} (Missed Ground Truth Events)\")\n",
    "    print(\"-\" * 28)\n",
    "    print(f\"Sensitivity (Recall):    {sensitivity:.3f}\")\n",
    "    print(f\"Precision:               {precision:.3f}\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "def plot_detection_comparison(data, true_positives, false_positives, false_negatives, sample_range=None):\n",
    "    \"\"\"Plots a section of data with detections and ground truth markers.\"\"\"\n",
    "    if sample_range is None:\n",
    "        sample_range = (0, min(10 * int(DATA_FS), len(data)))\n",
    "    \n",
    "    start_idx, end_idx = sample_range\n",
    "    time_axis = np.arange(start_idx, end_idx) / DATA_FS\n",
    "    \n",
    "    plt.figure(figsize=(18, 6))\n",
    "    ax = plt.gca()\n",
    "    plt.plot(time_axis, data[start_idx:end_idx], 'b-', alpha=0.6, label='Raw Data')\n",
    "    \n",
    "    # Plot detections and ground truth markers\n",
    "    all_gt_indices = [tp.matched_gt_index for tp in true_positives] + [fn[0] for fn in false_negatives]\n",
    "    gt_in_range = [idx for idx in all_gt_indices if start_idx <= idx < end_idx]\n",
    "    \n",
    "    # Use single representative lines for the legend\n",
    "    ax.axvline(x=-1, color='green', linestyle='--', label=f'Ground Truth ({len(all_gt_indices)})')\n",
    "    ax.axvline(x=-1, color='darkgreen', linestyle='-', label=f'True Positive ({len(true_positives)})')\n",
    "    ax.axvline(x=-1, color='red', linestyle='-', label=f'False Positive ({len(false_positives)})')\n",
    "\n",
    "    for gt_idx in gt_in_range:\n",
    "        ax.axvline(x=gt_idx / DATA_FS, color='green', linestyle='--', alpha=0.7)\n",
    "        \n",
    "    for det in true_positives + false_positives:\n",
    "        if start_idx <= det.index < end_idx:\n",
    "            color = 'darkgreen' if det.is_match else 'red'\n",
    "            ax.axvline(x=det.index / DATA_FS, color=color, linestyle='-', alpha=0.8)\n",
    "\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title('Detection Comparison: Raw Data, Ground Truth, and Detections')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xlim(time_axis[0], time_axis[-1])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- Main Execution ---\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    print(\"🧠 DirectNeuralBiasing Detection Comparison\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    create_config_file(CONFIG_PATH)\n",
    "\n",
    "    try:\n",
    "        # --- Setup ---\n",
    "        print(\"\\n📊 Loading and preparing data...\")\n",
    "        data = np.load(DATA_FILE_PATH)[0]\n",
    "        original_mrk_indices = parse_mrk_file(MRK_FILE_PATH)\n",
    "        ground_truth_map = get_ground_truth_map(original_mrk_indices)\n",
    "        print(f\"Loaded {len(data)} data samples and {len(ground_truth_map)} ground truth markers.\")\n",
    "        \n",
    "        # --- Processing ---\n",
    "        print(f\"\\n🔧 Initializing signal processor and starting live detection...\")\n",
    "        if SHOW_LIVE_PLOTS:\n",
    "            print(f\"📈 Live plotting is ENABLED (showing up to {MAX_LIVE_PLOTS if MAX_LIVE_PLOTS else 'all'} plots)\")\n",
    "        else:\n",
    "            print(\"📈 Live plotting is DISABLED\")\n",
    "        \n",
    "        processor = dnb.PySignalProcessor.from_config_file(CONFIG_PATH)\n",
    "        \n",
    "        true_positives, false_positives, false_negatives = process_and_report_events_live(\n",
    "            processor, data, ground_truth_map\n",
    "        )\n",
    "\n",
    "        # --- Final Reporting ---\n",
    "        print(\"\\n✅ Live processing complete.\")\n",
    "        print_summary_metrics(\n",
    "            len(true_positives),\n",
    "            len(false_positives),\n",
    "            len(false_negatives),\n",
    "            len(ground_truth_map)\n",
    "        )\n",
    "\n",
    "        # --- Visualization ---\n",
    "        print(f\"\\n🎨 Plotting final detection comparison...\")\n",
    "        plot_detection_comparison(data, true_positives, false_positives, false_negatives)\n",
    "    \n",
    "    finally:\n",
    "        # --- Cleanup ---\n",
    "        if os.path.exists(CONFIG_PATH):\n",
    "            os.remove(CONFIG_PATH)\n",
    "            print(f\"\\n🧹 Cleaned up: Deleted {CONFIG_PATH}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4afca-7e4a-41e5-86f0-f1e2e0f41fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
